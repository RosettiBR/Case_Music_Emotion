# Projeto: Decifrando Emo√ß√µes Musicais üéµ

Uma an√°lise preditiva com Machine Learning para classificar emo√ß√µes a partir de caracter√≠sticas de √°udio de m√∫sicas do Spotify. Este projeto foi desenvolvido como resposta a um desafio para explorar e comparar modelos de classifica√ß√£o.

## üéØ Objetivo

O objetivo principal deste projeto √© investigar a capacidade de modelos de Machine Learning, como **Regress√£o Log√≠stica** e **Random Forest**, em prever a emo√ß√£o principal transmitida por uma m√∫sica (`main_emotion`) utilizando suas caracter√≠sticas de √°udio fornecidas pelo Spotify.

## üíø O Dataset Utilizado

Os dados foram extra√≠dos do dataset **"500K+ Spotify Songs with Lyrics,Emotions & More"**, dispon√≠vel no [Kaggle](https://www.google.com/search?q=https://www.kaggle.com/datasets/suraj520/500k-spotify-songs-with-lyrics-emotions-more).

Dada a grande dimens√£o dos dados originais (+500 mil m√∫sicas), foi criada uma **amostra aleat√≥ria** para garantir a agilidade no pr√©-processing e na fase de treinamento dos modelos, permitindo um ciclo de experimenta√ß√£o mais r√°pido e eficiente.

## üõ†Ô∏è Estrutura e Fluxo de Trabalho do Projeto

O projeto foi organizado em dois notebooks sequenciais para garantir a separa√ß√£o de responsabilidades e a reprodutibilidade do processo:

1.  **`01_EDA_e_Pre-processamento.ipynb`**:

      * Carga dos dados brutos.
      * An√°lise Explorat√≥ria de Dados (EDA) para entender a distribui√ß√£o e as rela√ß√µes entre as features.
      * Limpeza, tratamento de valores ausentes e engenharia de features.
      * O resultado √© um DataFrame limpo e preparado para a modelagem.

2.  **`dados_limpos_para_modelagem.parquet`**:

      * Arquivo intermedi√°rio no formato Parquet, que armazena os dados processados de forma eficiente.

3.  **`02_Modelagem_e_Avaliacao.ipynb`**:

      * Carrega os dados processados do arquivo Parquet.
      * Divide os dados em conjuntos de treino e teste.
      * Aplica o escalonamento de features (`StandardScaler`).
      * Treina e avalia os modelos de classifica√ß√£o.
      * Compara a performance dos modelos para determinar o mais eficaz para o problema.

## üíª Tecnologias Utilizadas

  * **Python 3**
  * **Pandas e NumPy** para manipula√ß√£o de dados.
  * **Scikit-learn** para pr√©-processamento, modelagem e avalia√ß√£o.
  * **Matplotlib e Seaborn** para visualiza√ß√£o de dados.
  * **Jupyter Notebook** como ambiente de desenvolvimento.

## üìä Resultados e Desafios

Ap√≥s a fase de modelagem e avalia√ß√£o, o modelo que apresentou o melhor desempenho geral foi o **Random Forest**.

  * **Scores F1 (valida√ß√£o cruzada de 5 folds):** `[0.654, 0.657, 0.656, 0.655, 0.654]`
  * **M√©dia do F1-Score:** **0.6556**
  * **Desvio Padr√£o do F1-Score:** **0.0010**

### Matriz de Confus√£o - Random Forest

### An√°lise Cr√≠tica dos Desafios

Um dos principais desafios observados foi a dificuldade do modelo em assimilar as diferen√ßas entre classes muito semelhantes. Como pode ser visto na matriz de confus√£o, o modelo confundiu bastante as classes **1 (Joy)** e **3 (Negative Valence)**.

Isso sugere que, embora o Random Forest seja robusto para problemas multiclasse, as caracter√≠sticas de √°udio para essas duas emo√ß√µes s√£o muito parecidas, e o modelo n√£o conseguiu capturar suas peculiaridades sutis apenas com a engenharia de features inicial.

## üöÄ Conclus√µes e Pr√≥ximos Passos

Este projeto foi uma jornada de aprendizado valiosa, especialmente no que diz respeito √† import√¢ncia da engenharia de features e √† an√°lise cr√≠tica dos resultados de um modelo. Com base nos achados, os pr√≥ximos passos seriam focados mais no aprendizado do que puramente na performance:

1.  **Retornar ao Pr√©-processamento:** O pr√≥ximo passo l√≥gico seria aprofundar a engenharia de features, buscando "levantar" as diferen√ßas entre as classes problem√°ticas. Isso poderia envolver a cria√ß√£o de features polinomiais ou de intera√ß√£o (ex: combinar BPM com g√™nero musical) para fortalecer as caracter√≠sticas que separam "Joy" de "Negative Valence", ou at√© mesmo usar t√©cnicas como **An√°lise de Componentes Principais (PCA)** para criar features mais representativas.

2.  **Ajuste de Hiperpar√¢metros:** Explorar como os hiperpar√¢metros do Random Forest influenciam a cria√ß√£o dos n√≥s da √°rvore, buscando privilegiar as peculiaridades de cada classe.

3.  **Explorar Modelos de Boosting:** Como √∫ltimo recurso, caso os ajustes anteriores n√£o tragam melhorias satisfat√≥rias, uma abordagem seria utilizar modelos mais complexos e "apelativos" como **LightGBM**, **Gradient Boosting** ou **XGBoost**. No entanto, a prioridade seria esgotar o aprendizado com o Random Forest, visto que os modelos de boosting, apesar de potentes, podem mascarar a necessidade de um bom trabalho de feature engineering e demandam maior poder computacional.

## ‚öôÔ∏è Como Executar o Projeto

1.  Clone o reposit√≥rio:
    ```bash
    git clone https://github.com/RosettiBR/Case_Music_Emotion.git
    ```
2.  Crie um ambiente virtual e instale as depend√™ncias. Recomenda-se criar um arquivo `requirements.txt`.
3.  Baixe os dados do Kaggle e coloque-os em uma pasta `data/` na raiz do projeto.
4.  Execute os notebooks na ordem num√©rica: `01_EDA_e_Pre-processamento.ipynb` e, em seguida, `02_Modelagem_e_Avaliacao.ipynb`.
